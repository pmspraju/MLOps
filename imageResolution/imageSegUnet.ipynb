{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 09:29:24.106313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-01 09:29:24.862484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-01 09:29:24.862757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-01 09:29:24.862766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/pmspraju/.local/share/virtualenvs/imageResolution-c2hlZ-SW/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas:1.3.4, Numpy:1.21.4, Tensorflow:2.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfdata\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "from prefect import flow, task\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "\n",
    "print(f'Pandas:{pd.__version__}, Numpy:{np.__version__}, Tensorflow:{tf.__version__}')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "#print('Device:', tf.config.list_physical_devices('GPU'))\n",
    "#print(\"----Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_setup():\n",
    "    MLFLOW_TRACKING_URI =\"sqlite:////home/pmspraju/tracking-server/mlflow.db\" \n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def create_mlflow_experiment(experiment_name):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            experiment_name,\n",
    "            #artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
    "            artifact_location='//home/pmspraju/tracking-server/mlruns/',\n",
    "            tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "        )\n",
    "    except Exception as MlflowException:\n",
    "        print(f\"Experiment exists\")\n",
    "        experiment= mlflow.set_experiment(experiment_name)\n",
    "        # Examine the experiment details.\n",
    "        print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "        print(\"Name: {}\".format(experiment.name))\n",
    "        print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "        print(\"Tags: {}\".format(experiment.tags))\n",
    "        print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "        print(\"Last Updated timestamp: {}\".format(experiment.last_update_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the images in the dataset. We must also normalize the masks so that the classes are numbered from 0 through 2, \n",
    "# instead of from 1 through 3\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image, given an element from a TensorFlow dataset data structure. Note that we resize both the image and the mask to 256x256. \n",
    "# Also, if the train flag is set to True, we perform augmentation by randomly mirroring the image and its mask. \n",
    "# Finally, we normalize the inputs:\n",
    "@tf.function\n",
    "def load_image(dataset_element, train=True):\n",
    "\n",
    "    input_image = tf.image.resize(dataset_element['image'], (256, 256))\n",
    "    input_mask = tf.image.resize(dataset_element['segmentation_mask'],(256, 256))\n",
    "\n",
    "    if train and np.random.uniform() > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mlflow_image(name, remove_file=False):\n",
    "    work_dir = pathlib.Path('/home/pmspraju/MLOps/imageResolution')\n",
    "    img_path = os.path.join(work_dir, name)\n",
    "    im = Image.open(img_path)\n",
    "    mlflow.log_image(im, name)\n",
    "    \n",
    "    if remove_file:\n",
    "        os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class, UNet(), that will contain all the logic necessary to build, train, and evaluate our U-Net.\n",
    "class UNet(object):\n",
    "\n",
    "    # output_channels is, by default, 3, because each pixel can be categorized into one of three classes.\n",
    "    def __init__(self, input_size=(256, 256, 3), output_channels=3):\n",
    "        self.input_size = input_size\n",
    "        self.output_channels = output_channels\n",
    "        self.model = self._create_model()\n",
    "        loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.model.compile(optimizer=RMSprop(), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # This is a convolution that can be (optionally) batch normalized and that's activated with LeakyReLU:\n",
    "    @staticmethod\n",
    "    def _downsample(filters, size, batch_norm=True):\n",
    "\n",
    "        initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "        layers = Sequential()\n",
    "\n",
    "        layers.add(Conv2D(filters=filters,\n",
    "                          kernel_size=size,\n",
    "                          strides=2,\n",
    "                          padding='same',\n",
    "                          kernel_initializer=initializer,\n",
    "                          use_bias=False))\n",
    "        \n",
    "        if batch_norm:\n",
    "            layers.add(BatchNormalization())\n",
    "\n",
    "        layers.add(LeakyReLU())\n",
    "\n",
    "        return layers\n",
    "    \n",
    "    # the _upsample() helper method expands its input through a transposed convolution, which is also batch normalized \n",
    "    # and ReLU activated (optionally, we can add a dropout layer to prevent overfitting):\n",
    "    def _upsample(self, filters, size, drop_out=False):\n",
    "\n",
    "        init = tf.random_normal_initializer(0.0, 0.02)\n",
    "\n",
    "        layers = Sequential()\n",
    "\n",
    "        layers.add(Conv2DTranspose(filters=filters,\n",
    "                                    kernel_size=size,\n",
    "                                    strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=init,\n",
    "                                    use_bias=False))\n",
    "        \n",
    "        layers.add(BatchNormalization())\n",
    "\n",
    "        if drop_out:\n",
    "            layers.add(Dropout(rate=0.5))\n",
    "\n",
    "        layers.add(ReLU())\n",
    "\n",
    "        return layers\n",
    "    \n",
    "    # The encoding part of the network is just a stack of downsampling blocks\n",
    "    # the decoding portion is, as expected, comprised of a series of upsampling blocks\n",
    "    def _create_model(self):\n",
    "\n",
    "        down_stack = [self._downsample(64, 4, batch_norm=False)]\n",
    "\n",
    "        for filters in (128, 256, 512, 512, 512, 512, 512):\n",
    "            down_block = self._downsample(filters, 4)\n",
    "            down_stack.append(down_block)\n",
    "\n",
    "        up_stack = []\n",
    "        for _ in range(3):\n",
    "            up_block = self._upsample(512, 4, drop_out=True)\n",
    "            up_stack.append(up_block)\n",
    "\n",
    "        for filters in (512, 256, 128, 64):\n",
    "            up_block = self._upsample(filters, 4)\n",
    "            up_stack.append(up_block)\n",
    "\n",
    "        inputs = Input(shape=self.input_size)\n",
    "\n",
    "        x = inputs\n",
    "\n",
    "        skip_layers = []\n",
    "\n",
    "        for down in down_stack:\n",
    "            x = down(x)\n",
    "            skip_layers.append(x)\n",
    "\n",
    "        skip_layers = reversed(skip_layers[:-1])\n",
    "\n",
    "        for up, skip_connection in zip(up_stack, skip_layers):\n",
    "            x = up(x)\n",
    "            x = Concatenate()([x, skip_connection])\n",
    "\n",
    "        init = tf.random_normal_initializer(0.0, 0.02)\n",
    "        output = Conv2DTranspose(   filters=self.output_channels,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=init)(x)\n",
    "        \n",
    "        return Model(inputs, outputs=output)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _plot_model_history(model_history, metric, ylim=None):\n",
    "        \n",
    "        plt.style.use('seaborn-darkgrid')\n",
    "        plotter = tfdocs.plots.HistoryPlotter()\n",
    "        plotter.plot({'Model': model_history}, metric=metric)\n",
    "        plt.title(f'{metric.upper()}')\n",
    "\n",
    "        if ylim is None:\n",
    "            plt.ylim([0, 1])\n",
    "        else:\n",
    "            plt.ylim(ylim)\n",
    "\n",
    "        plt.savefig(f'{metric}.png')\n",
    "        plt.close()\n",
    "\n",
    "         # Log the image in mlflow\n",
    "        log_mlflow_image(f'{metric}.png', True)\n",
    "        \n",
    "\n",
    "    def train(self, train_dataset, epochs, steps_per_epoch, validation_dataset, validation_steps):\n",
    "        hist = self.model.fit(train_dataset,\n",
    "                                epochs=epochs,\n",
    "                                steps_per_epoch=steps_per_epoch,\n",
    "                                validation_steps=validation_steps,\n",
    "                                validation_data=validation_dataset)\n",
    "        \n",
    "        # write model summary\n",
    "        path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "        summary = []\n",
    "        self.model.summary(print_fn=summary.append)\n",
    "        summary = \"\\n\".join(summary)\n",
    "        summary_path = os.path.join(path, \"model_summary.txt\")\n",
    "        with open(summary_path, \"w\") as f:\n",
    "            f.write(summary)\n",
    "        mlflow.log_artifact(summary_path)\n",
    "        os.remove(summary_path)\n",
    "\n",
    "        # write model as json file\n",
    "        model_json_path = os.path.join(path, \"model.json\")\n",
    "        with open(model_json_path, \"w\") as f:\n",
    "            f.write(self.model.to_json())\n",
    "        mlflow.log_artifact(model_json_path)\n",
    "        os.remove(model_json_path)\n",
    "        \n",
    "        # log model in mlflow\n",
    "        input_schema = Schema([\n",
    "                            TensorSpec(np.dtype(np.uint8), (-1, 256, 256, 3)),\n",
    "                            ])\n",
    "        output_schema = Schema([TensorSpec(np.dtype(np.uint8), (-1, 256, 256, 3))])\n",
    "        signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "\n",
    "        mlflow.tensorflow.log_model(model=self.model,signature=signature,\n",
    "                                   artifact_path=\"tf-models\")\n",
    "        \n",
    "        \n",
    "        self._plot_model_history(hist, 'loss', [0., 2.0])\n",
    "        self._plot_model_history(hist, 'accuracy')\n",
    "        \n",
    "    @staticmethod\n",
    "    def _process_mask(mask):\n",
    "        mask = (mask.numpy() * 127.5).astype('uint8')\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def _save_image_and_masks(self, image, ground_truth_mask, prediction_mask, image_id):\n",
    "\n",
    "        image = (image.numpy() * 255.0).astype('uint8')\n",
    "        gt_mask = self._process_mask(ground_truth_mask)\n",
    "        pred_mask = self._process_mask(prediction_mask)\n",
    "\n",
    "        mosaic = np.hstack([image, gt_mask, pred_mask])\n",
    "        mosaic = cv2.cvtColor(mosaic, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imwrite(f'mosaic_{image_id}.jpg', mosaic)\n",
    "        log_mlflow_image(f'mosaic_{image_id}.jpg', True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_mask(prediction_mask):\n",
    "        prediction_mask = tf.argmax(prediction_mask, axis=-1)\n",
    "        prediction_mask = prediction_mask[...,tf.newaxis]\n",
    "        \n",
    "        return prediction_mask[0]\n",
    "\n",
    "    def _save_predictions(self, dataset, sample_size=1):\n",
    "\n",
    "        for id, (image, mask) in enumerate(dataset.take(sample_size), start=1):\n",
    "            pred_mask = self.model.predict(image)\n",
    "            pred_mask = self._create_mask(pred_mask)\n",
    "\n",
    "            image = image[0]\n",
    "            ground_truth_mask = mask[0]\n",
    "            self._save_image_and_masks(image, ground_truth_mask, pred_mask, image_id=id)\n",
    "\n",
    "    def evaluate(self, test_dataset, sample_size=5):\n",
    "\n",
    "        result = self.model.evaluate(test_dataset)\n",
    "        #print(f'Accuracy: {result[1] * 100:.2f}%')\n",
    "        mlflow.log_metric(\"Accuracy\", result[1] * 100)\n",
    "\n",
    "        self._save_predictions(test_dataset, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(AUTOTUNE, BUFFER_SIZE, BATCH_SIZE):\n",
    "\n",
    "    dataset, info = tfdata.load('oxford_iiit_pet', with_info=True)\n",
    "    #print(info)\n",
    "\n",
    "    TRAIN_SIZE = info.splits['train[:80%]'].num_examples\n",
    "    VALIDATION_SIZE = info.splits['test[:80%]'].num_examples\n",
    "\n",
    "    train_dataset = (dataset['train'].take(TRAIN_SIZE) #dataset['train']\n",
    "                        .map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "                        .cache()\n",
    "                        .shuffle(BUFFER_SIZE)\n",
    "                        .batch(BATCH_SIZE)\n",
    "                        .repeat()\n",
    "                        .prefetch(buffer_size=AUTOTUNE))\n",
    "    \n",
    "    test_dataset = (dataset['test'].take(VALIDATION_SIZE) #dataset['test']\n",
    "                    .map(lambda d: load_image(d, train=False), num_parallel_calls=AUTOTUNE)\n",
    "                    .batch(BATCH_SIZE))\n",
    "    \n",
    "    return train_dataset, test_dataset, TRAIN_SIZE, VALIDATION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, test_dataset, EPOCHS, STEPS_PER_EPOCH, VALIDATION_STEPS):\n",
    "\n",
    "    unet = UNet()\n",
    "    unet.train(train_dataset,\n",
    "                epochs=EPOCHS,\n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                validation_steps=VALIDATION_STEPS,\n",
    "                validation_dataset=test_dataset)\n",
    "    unet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main():\n",
    "    \n",
    "    client = mlflow_setup()\n",
    "    experiment_name = 'IMAGE-SEGMENTATION'\n",
    "    create_mlflow_experiment(experiment_name)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    BUFFER_SIZE = 1000\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    train_dataset, test_dataset, TRAIN_SIZE, VALIDATION_SIZE = load_data(AUTOTUNE, BUFFER_SIZE, BATCH_SIZE)\n",
    "\n",
    "    EPOCHS = 50\n",
    "    STEPS_PER_EPOCH = TRAIN_SIZE // BATCH_SIZE\n",
    "    VALIDATION_SUBSPLITS = 5\n",
    "    VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE\n",
    "    VALIDATION_STEPS //= VALIDATION_SUBSPLITS\n",
    "    \n",
    "    train_dataset, test_dataset, TRAIN_SIZE, VALIDATION_SIZE = load_data(AUTOTUNE, BUFFER_SIZE, BATCH_SIZE)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        \n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\",run.info.run_id)\n",
    "        print(\"  experiment_id:\",run.info.experiment_id)\n",
    "\n",
    "        mlflow.set_tag(\"version.mlflow\", mlflow.__version__)\n",
    "        mlflow.set_tag(\"version.tensorflow\", tf.__version__)\n",
    "\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"Train_size\", TRAIN_SIZE)\n",
    "        mlflow.log_param(\"Test_size\", VALIDATION_SIZE)\n",
    "\n",
    "        train_model(train_dataset, test_dataset, EPOCHS, STEPS_PER_EPOCH, VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:33.006 | INFO    | prefect.engine - Created flow run 'roaring-mule' for flow 'main'\n",
      "13:14:33.008 | INFO    | Flow run 'roaring-mule' - Using task runner 'SequentialTaskRunner'\n",
      "13:14:33.021 | WARNING | Flow run 'roaring-mule' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\n",
      "13:14:33.105 | INFO    | Flow run 'roaring-mule' - Created task run 'create_mlflow_experiment-863ae521-6' for task 'create_mlflow_experiment'\n",
      "13:14:33.191 | INFO    | Task run 'create_mlflow_experiment-863ae521-6' - Finished in state Completed()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exists\n",
      "Experiment_id: 4\n",
      "Name: IMAGE-SEGMENTATION\n",
      "Artifact Location: //home/pmspraju/tracking-server/mlruns/\n",
      "Tags: {'version': 'v1', 'priority': 'P1'}\n",
      "Lifecycle_stage: active\n",
      "Last Updated timestamp: 1679840590072\n",
      "MLflow:\n",
      "  run_id: 2f51f7a7377d48baac7c2a79d707d68a\n",
      "  experiment_id: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 703s 8s/step - loss: 0.7395 - accuracy: 0.6783 - val_loss: 0.7192 - val_accuracy: 0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:26:23.095 | WARNING | absl - Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8fpo0yz_/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:26:24.599 | INFO    | tensorflow - Assets written to: /tmp/tmp8fpo0yz_/model/data/model/assets\n",
      "/tmp/ipykernel_2086/2284606224.py:105: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n",
      "/home/pmspraju/.local/share/virtualenvs/imageResolution-c2hlZ-SW/lib/python3.9/site-packages/tensorflow_docs/plots/__init__.py:111: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  plt.xlim(\n",
      "/tmp/ipykernel_2086/2284606224.py:105: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n",
      "/home/pmspraju/.local/share/virtualenvs/imageResolution-c2hlZ-SW/lib/python3.9/site-packages/tensorflow_docs/plots/__init__.py:111: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  plt.xlim(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 238s 3s/step - loss: 0.7198 - accuracy: 0.7019\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:30:46.744 | INFO    | Flow run 'roaring-mule' - Finished in state Completed('All states completed.')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageResolution-c2hlZ-SW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "744a34a68aed0be7f165d9fabc8c1bc8fbffaff0c14db28a8c988df6d9e326c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
