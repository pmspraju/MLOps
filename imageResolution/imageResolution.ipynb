{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fc7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 11:54:39.617949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-26 11:54:39.617985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas:1.3.4, Numpy:1.21.4, Tensorflow:2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "print(f'Pandas:{pd.__version__}, Numpy:{np.__version__}, Tensorflow:{tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ed0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_setup():\n",
    "    MLFLOW_TRACKING_URI =\"sqlite:////home/pmspraju/tracking-server/mlflow.db\" \n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fd225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlflow_experiment(experiment_name):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            experiment_name,\n",
    "            #artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
    "            artifact_location='//home/pmspraju/tracking-server/mlruns/',\n",
    "            tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "        )\n",
    "    except Exception as MlflowException:\n",
    "        print(f\"Experiment exists\")\n",
    "        experiment= mlflow.set_experiment(experiment_name)\n",
    "        # Examine the experiment details.\n",
    "        print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "        print(\"Name: {}\".format(experiment.name))\n",
    "        print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "        print(\"Tags: {}\".format(experiment.tags))\n",
    "        print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "        print(\"Last Updated timestamp: {}\".format(experiment.last_update_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594fa49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize an image based on a scale factor. Take in to consideration that it receives an image represented as Numpy array.\n",
    "def resize_image(image_array, factor):\n",
    "    original_image = Image.fromarray(image_array)\n",
    "    new_size = np.array(original_image.size) * factor\n",
    "    new_size = new_size.astype(np.int32)\n",
    "    new_size = tuple(new_size)\n",
    "\n",
    "    resized = original_image.resize(new_size)\n",
    "    resized = img_to_array(resized)\n",
    "    resized = resized.astype(np.uint8)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f52f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tightly crop an image. We need the image to fit nicely when we apply a sliding window to extract patches later. \n",
    "# SCALE is the actor we want the network to learn how to enlarge images by\n",
    "def tight_crop_image(image, scale):\n",
    "    height, width = image.shape[:2]\n",
    "    width -= int(width % scale)\n",
    "    height -= int(height % scale)\n",
    "\n",
    "    return image[:height, :width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c841695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce resolution of an imae by downsizing and then upsizing \n",
    "def downsize_upsize_image(image, scale):\n",
    "    scaled = resize_image(image, 1.0 / scale)\n",
    "    scaled = resize_image(scaled, scale / 1.0)\n",
    "\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e4c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop patches from input images. input_dim is the height&width of the images that is input to the network\n",
    "def crop_input(image, x, y, input_dim):\n",
    "    x_slice = slice(x, x + input_dim)\n",
    "    y_slice = slice(y, y + input_dim)\n",
    "\n",
    "    return image[y_slice, x_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20aadf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop patches of output images. label_size is the height&width of the images output by the network. \n",
    "# pad is the number of pixels used as padding to ensure we are cropping the roi accurately\n",
    "def crop_output(image, x, y, label_size, pad):\n",
    "    y_slice = slice(y + pad, y + pad + label_size)\n",
    "    x_slice = slice(x + pad, x + pad + label_size)\n",
    "    #print(x, y , x_slice, y_slice)\n",
    "\n",
    "    return image[y_slice, x_slice]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa12726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to prepare data\n",
    "def prepare_data(path):\n",
    "    SEED = 999\n",
    "    SUBSET_SIZE = 100 #1500\n",
    "    SCALE = 2.0\n",
    "    INPUT_DIM = 33\n",
    "    LABEL_SIZE = 21\n",
    "    PAD = int((INPUT_DIM - LABEL_SIZE) / SCALE)\n",
    "    STRIDE = 14\n",
    "    \n",
    "    np.random.seed(SEED)\n",
    "    pattern = (path / 'images' / '*.png')\n",
    "    file_patterns = str(pattern)\n",
    "    dataset_paths = [*glob(file_patterns)]\n",
    "    \n",
    "    dataset_paths = np.random.choice(dataset_paths, SUBSET_SIZE)\n",
    "\n",
    "    data = []; labels = []; cnt = 0\n",
    "\n",
    "    for image_path in dataset_paths:\n",
    "        image = load_img(image_path)\n",
    "        image = img_to_array(image)\n",
    "        image = image.astype(np.uint8); #Image.fromarray(image).show()\n",
    "        image = tight_crop_image(image, SCALE); #Image.fromarray(image).show()\n",
    "        scaled = downsize_upsize_image(image, SCALE); #Image.fromarray(scaled).show()\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        #print(f'height:{height},width:{width}')\n",
    "        \n",
    "        for y in range(0, height - INPUT_DIM + 1, STRIDE):\n",
    "            for x in range(0, width - INPUT_DIM + 1, STRIDE):\n",
    "                crop = crop_input(scaled, x, y, INPUT_DIM); #Image.fromarray(crop).show()\n",
    "                target = crop_output(image, x, y, LABEL_SIZE, PAD);#Image.fromarray(target).show()\n",
    "                \n",
    "                #cnt = cnt + 1\n",
    "                \n",
    "                data.append(crop)#data.append(np.array(crop).flatten()) #use np.reshape(fi,(33,33,3)) to read        \n",
    "                labels.append(target)#labels.append(np.array(target).flatten());#use np.reshape(fi,(33,33,3)) to read  \n",
    "\n",
    "                #fname = f'train/images/image_{y}_{x}.png' \n",
    "                #Image.fromarray(crop).save(os.path.join(path,fname))   \n",
    "\n",
    "                #fname = f'train/labels/label_{y}_{x}.png'              \n",
    "                #Image.fromarray(target).save(os.path.join(path,fname)) \n",
    "                #break\n",
    "            #break\n",
    "        #break\n",
    "    #print(cnt)    \n",
    "    return [data, labels]\n",
    "    #pd.DataFrame({'image': data, 'label': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de48aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data\n",
    "# path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "# [data, labels] = prepare_data(path)\n",
    "# print(f'shape:{np.array(labels).shape}')\n",
    "# print(f'shape:{np.array(data).shape}')\n",
    "# labels = tf.convert_to_tensor(labels, np.int32)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80859c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, depth):\n",
    "    input = Input(shape=(height, width, depth))\n",
    "\n",
    "    x = Conv2D(filters=64, \n",
    "               kernel_size=(9,9),\n",
    "               kernel_initializer='he_normal'\n",
    "               ) (input)\n",
    "    \n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, \n",
    "               kernel_size=(1,1),\n",
    "               kernel_initializer='he_normal'\n",
    "                ) (x)\n",
    "\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    output = Conv2D(filters=depth, \n",
    "                    kernel_size=(5,5),\n",
    "                    kernel_initializer='he_normal'\n",
    "                    ) (x)\n",
    "\n",
    "    return Model(input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca9d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dim):\n",
    "    path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "    [data, labels] = prepare_data(path)\n",
    "    data = tf.convert_to_tensor(data, np.int32)\n",
    "    labels = tf.convert_to_tensor(labels, np.int32)\n",
    "    print(f'Data shape:{data.shape}, Labels shape\"{labels.shape}')\n",
    "\n",
    "    EPOCHS = 1 #12\n",
    "    optimizer = Adam(learning_rate=1e-3, decay=1e-3 / EPOCHS)\n",
    "    model = build_model(dim, dim, 3)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    BATCH_SIZE = 64\n",
    "    \n",
    "    model.fit(data, labels, batch_size=BATCH_SIZE, epochs = EPOCHS)\n",
    "\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "    key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    saved_model_path = os.path.join(path, )\n",
    "\n",
    "    mlflow.tensorflow.log_model(model=model,\n",
    "                                artifact_path=\"tf-models\")\n",
    "\n",
    "    # write model summary\n",
    "    summary = []\n",
    "    model.summary(print_fn=summary.append)\n",
    "    summary = \"\\n\".join(summary)\n",
    "    summary_path = os.path.join(path, \"model_summary.txt\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(summary)\n",
    "    mlflow.log_artifact(summary_path)\n",
    "    os.remove(summary_path)\n",
    "\n",
    "    # write model as json file\n",
    "    model_json_path = os.path.join(path, \"model.json\")\n",
    "    with open(model_json_path, \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "    mlflow.log_artifact(model_json_path)\n",
    "    os.remove(model_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d3490ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    experiment_name = 'IMAGE-RESOLUTION'\n",
    "    dim = 33\n",
    "    client = mlflow_setup()\n",
    "    create_mlflow_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\",run.info.run_id)\n",
    "        print(\"  experiment_id:\",run.info.experiment_id)\n",
    "        mlflow.set_tag(\"version.mlflow\", mlflow.__version__)\n",
    "        mlflow.set_tag(\"version.tensorflow\", tf.__version__)\n",
    "        train_model(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d1f010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exists\n",
      "Experiment_id: 3\n",
      "Name: IMAGE-RESOLUTION\n",
      "Artifact Location: //home/pmspraju/tracking-server/mlruns/\n",
      "Tags: {'version': 'v1', 'priority': 'P1'}\n",
      "Lifecycle_stage: active\n",
      "Last Updated timestamp: 1674755884516\n",
      "MLflow:\n",
      "  run_id: 7f80f63bb25846f9bdf391a920727660\n",
      "  experiment_id: 3\n",
      "Data shape:(67477, 33, 33, 3), Labels shape\"(67477, 21, 21, 3)\n",
      "1055/1055 [==============================] - 67s 63ms/step - loss: 222.2619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/26 12:01:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2023-01-26 12:01:42.255382: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpeto0xin3/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmspraju/.local/share/virtualenvs/imageResolution-c2hlZ-SW/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2f26238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook imageResolution.ipynb to script\n",
      "[NbConvertApp] Writing 6499 bytes to imageResolution.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script imageResolution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acec73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "    # df = prepare_data(path)\n",
    "    # with open(os.path.join(path,'train.txt'), 'wb') as fp:\n",
    "    #     pickle.dump(df[0], fp, pickle.HIGHEST_PROTOCOL)\n",
    "    #np.savetxt(os.path.join(path,'train.txt'), df.values, fmt='%d')\n",
    "    # with open(os.path.join(path,'train.txt'), 'a') as f:\n",
    "    #     dfAsString = df.to_string(header=False, index=False)\n",
    "    #     f.write(dfAsString)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageResolution-c2hlZ-SW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "744a34a68aed0be7f165d9fabc8c1bc8fbffaff0c14db28a8c988df6d9e326c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
