{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41fc7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas:1.3.4, Numpy:1.21.4, Tensorflow:2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import pathlib\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "from prefect import flow, task\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "\n",
    "print(f'Pandas:{pd.__version__}, Numpy:{np.__version__}, Tensorflow:{tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ed0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_setup():\n",
    "    MLFLOW_TRACKING_URI =\"sqlite:////home/pmspraju/tracking-server/mlflow.db\" \n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fd225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def create_mlflow_experiment(experiment_name):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            experiment_name,\n",
    "            #artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
    "            artifact_location='//home/pmspraju/tracking-server/mlruns/',\n",
    "            tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "        )\n",
    "    except Exception as MlflowException:\n",
    "        print(f\"Experiment exists\")\n",
    "        experiment= mlflow.set_experiment(experiment_name)\n",
    "        # Examine the experiment details.\n",
    "        print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "        print(\"Name: {}\".format(experiment.name))\n",
    "        print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "        print(\"Tags: {}\".format(experiment.tags))\n",
    "        print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "        print(\"Last Updated timestamp: {}\".format(experiment.last_update_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594fa49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize an image based on a scale factor. Take in to consideration that it receives an image represented as Numpy array.\n",
    "def resize_image(image_array, factor):\n",
    "    original_image = Image.fromarray(image_array)\n",
    "    new_size = np.array(original_image.size) * factor\n",
    "    new_size = new_size.astype(np.int32)\n",
    "    new_size = tuple(new_size)\n",
    "\n",
    "    resized = original_image.resize(new_size)\n",
    "    resized = img_to_array(resized)\n",
    "    resized = resized.astype(np.uint8)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f52f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tightly crop an image. We need the image to fit nicely when we apply a sliding window to extract patches later. \n",
    "# SCALE is the actor we want the network to learn how to enlarge images by\n",
    "def tight_crop_image(image, scale):\n",
    "    height, width = image.shape[:2]\n",
    "    width -= int(width % scale)\n",
    "    height -= int(height % scale)\n",
    "\n",
    "    return image[:height, :width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c841695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce resolution of an imae by downsizing and then upsizing \n",
    "def downsize_upsize_image(image, scale):\n",
    "    scaled = resize_image(image, 1.0 / scale)\n",
    "    scaled = resize_image(scaled, scale / 1.0)\n",
    "\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e4c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop patches from input images. input_dim is the height&width of the images that is input to the network\n",
    "def crop_input(image, x, y, input_dim):\n",
    "    x_slice = slice(x, x + input_dim)\n",
    "    y_slice = slice(y, y + input_dim)\n",
    "\n",
    "    return image[y_slice, x_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20aadf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop patches of output images. label_size is the height&width of the images output by the network. \n",
    "# pad is the number of pixels used as padding to ensure we are cropping the roi accurately\n",
    "def crop_output(image, x, y, label_size, pad):\n",
    "    y_slice = slice(y + pad, y + pad + label_size)\n",
    "    x_slice = slice(x + pad, x + pad + label_size)\n",
    "    #print(x, y , x_slice, y_slice)\n",
    "\n",
    "    return image[y_slice, x_slice]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa12726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to prepare data\n",
    "#@task\n",
    "def prepare_data(path):\n",
    "    SEED = 999\n",
    "    SUBSET_SIZE = 100 #1500\n",
    "    SCALE = 2.0\n",
    "    INPUT_DIM = 33\n",
    "    LABEL_SIZE = 21\n",
    "    PAD = int((INPUT_DIM - LABEL_SIZE) / SCALE)\n",
    "    STRIDE = 14\n",
    "    \n",
    "    np.random.seed(SEED)\n",
    "    pattern = (path / 'images' / '*.png')\n",
    "    file_patterns = str(pattern)\n",
    "    dataset_paths = [*glob(file_patterns)]\n",
    "    \n",
    "    dataset_paths = np.random.choice(dataset_paths, SUBSET_SIZE)\n",
    "\n",
    "    data = []; labels = []; cnt = 0\n",
    "\n",
    "    for image_path in dataset_paths:\n",
    "        image = load_img(image_path)\n",
    "        image = img_to_array(image)\n",
    "        image = image.astype(np.uint8); #Image.fromarray(image).show()\n",
    "        image = tight_crop_image(image, SCALE); #Image.fromarray(image).show()\n",
    "        scaled = downsize_upsize_image(image, SCALE); #Image.fromarray(scaled).show()\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        #print(f'height:{height},width:{width}')\n",
    "        \n",
    "        for y in range(0, height - INPUT_DIM + 1, STRIDE):\n",
    "            for x in range(0, width - INPUT_DIM + 1, STRIDE):\n",
    "                crop = crop_input(scaled, x, y, INPUT_DIM); #Image.fromarray(crop).show()\n",
    "                target = crop_output(image, x, y, LABEL_SIZE, PAD);#Image.fromarray(target).show()\n",
    "                \n",
    "                #cnt = cnt + 1\n",
    "                \n",
    "                data.append(crop)#data.append(np.array(crop).flatten()) #use np.reshape(fi,(33,33,3)) to read        \n",
    "                labels.append(target)#labels.append(np.array(target).flatten());#use np.reshape(fi,(33,33,3)) to read  \n",
    "\n",
    "                #fname = f'train/images/image_{y}_{x}.png' \n",
    "                #Image.fromarray(crop).save(os.path.join(path,fname))   \n",
    "\n",
    "                #fname = f'train/labels/label_{y}_{x}.png'              \n",
    "                #Image.fromarray(target).save(os.path.join(path,fname)) \n",
    "                #break\n",
    "            #break\n",
    "        #break\n",
    "    #print(cnt)    \n",
    "    return [data, labels]\n",
    "    #pd.DataFrame({'image': data, 'label': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de48aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data\n",
    "# path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "# [data, labels] = prepare_data(path)\n",
    "# print(f'shape:{np.array(labels).shape}')\n",
    "# print(f'shape:{np.array(data).shape}')\n",
    "# labels = tf.convert_to_tensor(labels, np.int32)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80859c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task #- task cannot be called inside another task\n",
    "def build_model(height, width, depth):\n",
    "    input = Input(shape=(height, width, depth))\n",
    "\n",
    "    x = Conv2D(filters=64, \n",
    "               kernel_size=(9,9),\n",
    "               kernel_initializer='he_normal'\n",
    "               ) (input)\n",
    "    \n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(filters=32, \n",
    "               kernel_size=(1,1),\n",
    "               kernel_initializer='he_normal'\n",
    "                ) (x)\n",
    "\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    output = Conv2D(filters=depth, \n",
    "                    kernel_size=(5,5),\n",
    "                    kernel_initializer='he_normal'\n",
    "                    ) (x)\n",
    "\n",
    "    return Model(input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca9d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def train_model(path, dim,  data, labels, model):\n",
    "    data = tf.convert_to_tensor(data, np.int32)\n",
    "    labels = tf.convert_to_tensor(labels, np.int32)\n",
    "    print(f'Data shape:{data.shape}, Labels shape\"{labels.shape}')\n",
    "\n",
    "    EPOCHS = 1 #12\n",
    "    optimizer = Adam(learning_rate=1e-3, decay=1e-3 / EPOCHS)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    BATCH_SIZE = 64\n",
    "    \n",
    "    model.fit(data, labels, batch_size=BATCH_SIZE, epochs = EPOCHS)\n",
    "\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    input_schema = Schema([\n",
    "                            TensorSpec(np.dtype(np.uint8), (-1, dim, dim, 3)),\n",
    "                            ])\n",
    "    output_schema = Schema([TensorSpec(np.dtype(np.uint8), (-1, 21, 21, 3))])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "\n",
    "    mlflow.tensorflow.log_model(model=model,signature=signature,\n",
    "                                artifact_path=\"tf-models\")\n",
    "\n",
    "    # write model summary\n",
    "    summary = []\n",
    "    model.summary(print_fn=summary.append)\n",
    "    summary = \"\\n\".join(summary)\n",
    "    summary_path = os.path.join(path, \"model_summary.txt\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(summary)\n",
    "    mlflow.log_artifact(summary_path)\n",
    "    os.remove(summary_path)\n",
    "\n",
    "    # write model as json file\n",
    "    model_json_path = os.path.join(path, \"model.json\")\n",
    "    with open(model_json_path, \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "    mlflow.log_artifact(model_json_path)\n",
    "    os.remove(model_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d3490ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(task_runner=SequentialTaskRunner())\n",
    "def main():\n",
    "    path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "    experiment_name = 'IMAGE-RESOLUTION'\n",
    "    dim = 33\n",
    "    client = mlflow_setup()\n",
    "    create_mlflow_experiment(experiment_name)\n",
    "    [data, labels] = prepare_data(path)\n",
    "    model = build_model(dim, dim, 3)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\",run.info.run_id)\n",
    "        print(\"  experiment_id:\",run.info.experiment_id)\n",
    "        mlflow.set_tag(\"version.mlflow\", mlflow.__version__)\n",
    "        mlflow.set_tag(\"version.tensorflow\", tf.__version__)\n",
    "        train_model(path, dim, data, labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d1f010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:50.852 | INFO    | prefect.engine - Created flow run 'psychedelic-elk' for flow 'main'\n",
      "13:01:50.854 | INFO    | Flow run 'psychedelic-elk' - Using task runner 'SequentialTaskRunner'\n",
      "13:01:50.866 | WARNING | Flow run 'psychedelic-elk' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\n",
      "13:01:50.944 | INFO    | Flow run 'psychedelic-elk' - Created task run 'create_mlflow_experiment-863ae521-1' for task 'create_mlflow_experiment'\n",
      "13:01:51.026 | INFO    | Task run 'create_mlflow_experiment-863ae521-1' - Finished in state Completed()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exists\n",
      "Experiment_id: 3\n",
      "Name: IMAGE-RESOLUTION\n",
      "Artifact Location: //home/pmspraju/tracking-server/mlruns/\n",
      "Tags: {'version': 'v1', 'priority': 'P1'}\n",
      "Lifecycle_stage: active\n",
      "Last Updated timestamp: 1674755884516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:53.148 | INFO    | Flow run 'psychedelic-elk' - Created task run 'build_model-074892a9-0' for task 'build_model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 13:01:54.394787: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-29 13:01:54.395033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-72LU0U0G): /proc/driver/nvidia/version does not exist\n",
      "2023-01-29 13:01:54.396675: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "13:01:54.495 | WARNING | tensorflow - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2023-01-29 13:01:54.749563: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4712e70b-71b3-4340-87e1-8a8ff50432e2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:01:55.111 | INFO    | tensorflow - Assets written to: ram://4712e70b-71b3-4340-87e1-8a8ff50432e2/assets\n",
      "13:01:55.176 | INFO    | Task run 'build_model-074892a9-0' - Finished in state Completed()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow:\n",
      "  run_id: 62d1d5f0b17f481bb14050047d8de998\n",
      "  experiment_id: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02:00.344 | INFO    | Flow run 'psychedelic-elk' - Created task run 'train_model-7c866860-0' for task 'train_model'\n",
      "2023-01-29 13:02:05.241738: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 881789436 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:(67477, 33, 33, 3), Labels shape\"(67477, 21, 21, 3)\n",
      "1055/1055 [==============================] - 62s 59ms/step - loss: 253.0873\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphtxhn1s7/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:37.107 | INFO    | tensorflow - Assets written to: /tmp/tmphtxhn1s7/model/data/model/assets\n",
      "/home/pmspraju/.local/share/virtualenvs/imageResolution-c2hlZ-SW/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "13:04:41.072 | INFO    | Task run 'train_model-7c866860-0' - Finished in state Completed()\n",
      "13:04:41.129 | INFO    | Flow run 'psychedelic-elk' - Finished in state Completed('All states completed.')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2f26238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook imageResolution.ipynb to script\n",
      "[NbConvertApp] Writing 6499 bytes to imageResolution.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script imageResolution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acec73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = pathlib.Path('/mnt/c/Users/pmspr/Documents/Machine Learning/Courses/Tensorflow Cert/Data/dogscats')\n",
    "# df = prepare_data(path)\n",
    "# with open(os.path.join(path,'train.txt'), 'wb') as fp:\n",
    "#     pickle.dump(df[0], fp, pickle.HIGHEST_PROTOCOL)\n",
    "#np.savetxt(os.path.join(path,'train.txt'), df.values, fmt='%d')\n",
    "# with open(os.path.join(path,'train.txt'), 'a') as f:\n",
    "#     dfAsString = df.to_string(header=False, index=False)\n",
    "#     f.write(dfAsString)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageResolution-c2hlZ-SW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "744a34a68aed0be7f165d9fabc8c1bc8fbffaff0c14db28a8c988df6d9e326c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
